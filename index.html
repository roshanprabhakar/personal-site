<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Roshan</title>
    <link href="css/style.css" rel="stylesheet">

    <!-- custom font: montserrat-->
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@100&display=swap" rel="stylesheet">
    <link href="https://unpkg.com/aos@2.3.1/dist/aos.css" rel="stylesheet">

</head>

<body>

<!--Title-->
<div id="header">
    <img src="res/portrait.png" alt="roshan" data-aos="fade-up">
    <!--    <div id="subheader">-->
    <h1 data-aos="fade-up">Roshan Prabhakar</h1>
    <h2 style="color:Orange" data-aos="fade-up">Research Experience</h2>
    <!--    </div>-->
</div>

<div class="work-experience">

    <!--Digital Puppetry-->
		<div id="digital-puppetry-iddiv"></div>
    <table id="digital-puppetry" data-aos="fade-up">
        <tr>
            <th class="title"></th>
            <th class="content project-title colored">Digital Puppetry</th>
        </tr>
        <tr>
            <th class="title colored">affiliation</th>
						<th class="content">
							<a href="https://taps.stanford.edu/" class="colored">Stanford Theater and Performing Arts</a>, 
							<a href="https://ee.stanford.edu" class="colored">Stanford Electrical Engineering</a>,
							<a href="https://cs.stanford.edu" class="colored">Stanford Computer Science</a>
            </th>
        </tr>
        <tr>
            <th class="title colored">title</th>
            <th class="content">Developer</th>
        </tr>
        <tr>
            <th class="title colored">timeline</th>
            <th class="content">August 2020 - December 2020</th>
        </tr>
        <tr>
            <th class="title colored">team</th>
            <th class="content">Prof. Tsachy Weissman (Stanford EE); Prof. Michael Rau (Stanford TAPS); Shubham Chandak & Kedar Tatwawadi, PhD students (Stanford EE)
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">background</th>
            <th class="content">Invited due to the success of the Keypoint-Centric Video Encoding group for STEM
                to SHTEM 2020, a group I mentored. 
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">summary</th>
            <th class="content">A collaborative effort among researchers in CS, EE, and TAPS to design software
                facilitating a live virtual theater production at Stanford University (Winter Quarter). This project was in close collaboration with the leadership
								of Stanford's CS349/EE192T, a course dedicated to building the infrastructure of the virtual stage. 
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">publication</th>
            <th class="content">
                <ul>
                    <li>Stanford Course: <a href="https://stagecast.stanford.edu/" class="colored">https://stagecast.stanford.edu/</a>
                    </li>
                </ul>
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">abstract</th>
            <th class="content">This project aims to implement a performance tool to allow stage-cast theater to
                continue functioning under lockdown constraints, with software that improves on modern standards:
                reducing data latencies over unreliable internet connections, and providing novel artistic abstraction
                tools. We built communication frameworks for the transmission of facemesh and pose skeletons,
                which can be reconstructed by a decoder as a digital puppet (avatar).
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">project</th>
            <th class="content">
                <ul>
                    <li><a href="https://github.com/roshanprabhakar/digital-puppetry" class="colored">https://github.com/roshanprabhakar/digital-puppetry</a>
                    </li>
                    <li><a href="https://github.com/shubhamchandak94/digital-puppetry" class="colored">https://github.com/shubhamchandak94/digital-puppetry</a>
                    </li>
                    <li><a href="https://github.com/shubhamchandak94/webrtc-signaling-server" class="colored">https://github.com/shubhamchandak94/webrtc-signaling-server</a>
                    </li>
                </ul>
            </th>
        </tr>
    </table>

    <!--ProtographLDPC-->
		<div id="protograph-ldpc-iddiv"></div>
    <table id="protograph-ldpc" data-aos="fade-up">
        <tr>
            <th class="title"></th>
            <th class="content project-title colored">ProtographLDPC</th>
        </tr>
        <tr>
            <th class="title colored">affiliation</th>
            <th class="content">
							<a href="https://ee.stanford.edu" class="colored">Stanford Electrical Engineering</a>, 
							<a href="https://isl.stanford.edu" class="colored">Stanford Information Systems Laboratory</a>
            </th>
        </tr>
        <tr>
            <th class="title colored">title</th>
            <th class="content">Research/Project Intern</th>
        </tr>
        <tr>
            <th class="title colored">timeline</th>
            <th class="content">February 2020 - November 2020</th>
        </tr>
        <tr>
            <th class="title colored">team</th>
            <th class="content">Prof. Tsachy Weissman (Stanford EE); Kedar Tatwawadi & Shubham Chandak, PhD students (Stanford EE)
            </th>
        </tr>
        <tr>
            <th class="title colored">background</th>
            <th class="content">Invited upon extending and completing my STEM to SHTEM 2019 project during the school
                year individually.
            </th>
        </tr>
        <tr>
            <th class="title colored">summary</th>
            <th class="content">Developed an open-source library for the handling and testing of Protograph-based LDPC
                codes aimed for easy usage and library extension.
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">publication</th>
            <th class="content">
                <ul>
                    <li>Featured in Radford Neal’s base library for Regular LDPC Codes -
                        <a href="https://github.com/radfordneal/LDPC-codes" class="colored">https://github.com/radfordneal/LDPC-codes</a>
                    </li>
                    <li>Prof. Tsachy Weissman academic website - <a
                            href="https://web.stanford.edu/~tsachy/software.html" class="colored">https://web.stanford.edu/~tsachy/software.html</a>
                    </li>
                    <li>The Informaticists Scientific Journal - <a
                            href="https://theinformaticists.com/tag/2020/"
                            class="colored">https://theinformaticists.com/2021/08/21/facial-landmark-data-collection-to-train-facial-emotion-detection-learning-models/</a>
                    </li>
                    <li>Zenodo - <a href="https://zenodo.org/record/4016076" class="colored">https://zenodo.org/record/4016076</a>
                    </li>
                    <li>OpenAIRE - <a
                            href="https://explore.openaire.eu/search/software?softwareId=r37b0ad08687::1cc6ba2cbf7ade94cb8ba39878ecb4c3"
                            class="colored">https://explore.openaire.eu/search/software?softwareId=r37b0ad08687::1cc6ba2cbf7ade94cb8ba39878ecb4c3</a>
                    </li>
                </ul>
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">abstract</th>
            <th class="content">Protograph-based LDPC codes are a class of high performance linear error-correction
                codes on sparse bipartite graphs providing efficient decoding using message passing (between variable
                and check nodes on the graph). My group’s work provides an API to handle these codes, built upon Prof.
                Radford Neal’s library for the handling of regular LDPC codes.<br>

                Functionality included for:<br>
                - Generation of regular and protograph LDPC matrices using PEG and library custom construction
                methods.<br>
                - Encoding and decoding of these codes, including support for puncturing.<br>
                - Utility and test scripts for analyzing these codes.

            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">project</th>
            <th class="content">
                <ul>
                    <li><a href="https://shubhamchandak94.github.io/ProtographLDPC/" class="colored">https://shubhamchandak94.github.io/ProtographLDPC/</a>
                    </li>
                    <li><a href="https://github.com/shubhamchandak94/ProtographLDPC" class="colored">https://github.com/shubhamchandak94/ProtographLDPC</a>
                    </li>
                </ul>
            </th>
        </tr>
    </table>

    <!--Keypoint-centric video encoding-->
		<div id="scf20-iddiv"></div>
    <table id="scf20" data-aos="fade-up">
        <tr>
            <th class="title"></th>
            <th class="content project-title colored">Keypoint-centric Encoding</th>
        </tr>
        <tr>
            <th class="title colored">affiliation</th>
            <th class="content">
							<a href="https://isl.stanford.edu/" class="colored">Stanford Information Systems Laboratory</a>, 
							<a href="https://compression.stanford.edu" class="colored">Stanford Compression Forum</a>,
							<a href="https://compression.stanford.edu/outreach/stem2shtem-summer-internships-high-schoolers-and-community-college-students" class="colored">Stanford STEM to SHTEM</a>
            </th>
        </tr>
        <tr>
            <th class="title colored">title</th>
            <th class="content">Research/Project Mentor</th>
        </tr>
        <tr>
            <th class="title colored">timeline</th>
            <th class="content">June 2020 - August 2020</th>
        </tr>
        <tr>
            <th class="title colored">advisors</th>
            <th class="content">Prof. Tsachy Weissman (Stanford EE); Shubham Chandak, PhD student (Stanford EE)</th>
        </tr>
        <tr>
            <th class="title colored">background</th>
            <th class="content">Invited to mentor a group of highschool interns for STEM to SHTEM 2020 due to my involvement at Stanford ISL.</th>
        </tr>
        <tr>
            <th class="title colored">summary</th>
            <th class="content">Led the development of a proof of concept for a novel redesign of the conventional video
                streaming pipeline aiming to reduce net latency in video streams. This work inspired and became foundational 
								to the Stanford Digital Puppetry Project.
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">publication</th>
            <th class="content">
                <ul>
                    <li>The Informaticists Scientific Journal - <a
                            href="https://theinformaticists.com/2020/08/25/keypoint-centric-video-processing-for-reducing-net-latency-in-video-streaming/"
                            class="colored">https://theinformaticists.com/2020/08/25/keypoint-centric-video-processing-for-reducing-net-latency-in-video-streaming/</a>
                    </li>
                    <li>Presented at the 2021 (D)ata (C)ompression (C)onference - <a
                            href="https://sigport.org/documents/reducing-latency-and-bandwidth-video-streaming-using-keypoint-extraction-and-digital"
                            class="colored">https://sigport.org/documents/reducing-latency-and-bandwidth-video-streaming-using-keypoint-extraction-and-digital</a>
                    </li>

                    <li>Arxiv -
                        <ul>
                            <li><a href="https://arxiv.org/abs/2011.03800" class="colored">https://arxiv.org/abs/2011.03800</a>
                            </li>
                            <li><a href="https://arxiv.org/pdf/2011.03800.pdf" class="colored">https://arxiv.org/pdf/2011.03800.pdf</a>
                            </li>
                        </ul>
                    </li>
                    <li>Invited to present at Stanford’s SystemX Alliance 2020 Conference as a student of Prof. Tsachy
                        Weissman - <a
                                href="https://systemx.stanford.edu/events/annual-conference/20201021/systemx-november-conference-oct-21-nov-11-2020"
                                class="colored">https://systemx.stanford.edu/events/annual-conference/20201021/systemx-november-conference-oct-21-nov-11-2020</a>
                    </li>
                    <li>Stanford Compression Forum - <a href="https://compression.stanford.edu/projects/video-streaming-puppets"
                                                        class="colored">https://compression.stanford.edu/projects/video-streaming-puppets</a>
                    </li>
                    <li>Invited to present at Stanford’s 2021 Compression Workshop<a
                            href="https://compression.stanford.edu/stanford-compression-workshop-2021"
                            class="colored">https://compression.stanford.edu/stanford-compression-workshop-2021</a>
                    </li>
                </ul>
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">abstract</th>
            <th class="content">This project focuses on reducing net latency in video streams by exploring different
                configurations of the streaming pipeline and video encoding schema. The prototype extracts and transmits
                video-specific keypoints related to the reconstruction of client-end animations, achieving a drastic
                reduction in transmitted data under much lesser network bandwidth requirements than the conventional
                video streaming model.
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">project</th>
            <th class="content">
                <ul>
                    <li><a href="https://github.com/roshanprabhakar/pose-animator-stream/tree/master" class="colored">https://github.com/roshanprabhakar/pose-animator-stream/tree/master</a>
                    </li>
										<li><a href="https://github.com/roshanprabhakar/WebRTC-Framework" class="colored">https://github.com/roshanprabhakar/WebRTC-Framework</a>
										</li>
                </ul>
            </th>
        </tr>
    </table>

    <!--HAAC Image Compressor-->
		<div id="scf19-iddiv"></div>
    <table id="scf19" data-aos="fade-up">
        <tr>
            <th class="title"></th>
            <th class="content project-title colored">Facial-centric Image Compression</th>
        </tr>
        <tr>
            <th class="title colored">affiliation</th>
            <th class="content">
							<a href="https://isl.stanford.edu/" class="colored">Stanford Information Systems Laboratory</a>, 
							<a href="https://compression.stanford.edu" class="colored">Stanford Compression Forum</a>,
							<a href="https://compression.stanford.edu/outreach/stem2shtem-summer-internships-high-schoolers-and-community-college-students" class="colored">Stanford STEM to SHTEM</a>
            </th>
        </tr>
        <tr>
            <th class="title colored">title</th>
            <th class="content">Research/Project Intern</th>
        </tr>
        <tr>
            <th class="title colored">timeline</th>
            <th class="content">June 2019 - August 2019</th>
        </tr>
        <tr>
            <th class="title colored">advisors</th>
            <th class="content">Prof. Tsachy Weissman (Stanford EE); Kedar Tatwawadi, PhD student (Stanford EE); Sarah Abdali, Stanford Undergrad</th>
        </tr>
        <tr>
            <th class="title colored">summary</th>
            <th class="content">Collaborated with high school peers to develop a novel compression algorithm for facial
                images. Continued this project individually upon the program’s end. This was a first foray into information theory.
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">publication</th>
            <th class="content">
                <ul>
                    <li>The Informaticists Scientific Journal - <a
                            href="https://theinformaticists.com/2019/08/28/building-a-human-centric-lossy-compressor-for-facial-images/"
                            class="colored">https://theinformaticists.com/2019/08/28/building-a-human-centric-lossy-compressor-for-facial-images/</a>
                    </li>
                </ul>
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">abstract</th>
            <th class="content">This project capitalizes on the idea that the eyes, nose, and mouth are of utmost
                importance for identity preservation in facial images. The initial implementation posed a rescaling
                compression of the image alongside full preservation of facial features. I additionally put together 
								a k-means based	refining algorithm to operate on the output of the primary viola-jones cascades.
								Following the STEM to SHTEM program’s conclusion, I developed k-means clustering based jpeg compression 
								for the purposes of edge preservation in the resultant image, aiming to improve the existing schema. Multi-level compression was
                later implemented: the image background, facial background, and features being subjected to different
                degrees of compression.
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">project</th>
            <th class="content">
                <ul>
                    <li><a href="https://github.com/roshanprabhakar/FacialHAAC" class="colored">https://github.com/roshanprabhakar/FacialHAAC</a>
                    </li>
                    <li><a href="https://github.com/roshanprabhakar/facial-haac-2" class="colored">https://github.com/roshanprabhakar/facial-haac-2</a>
                    </li>
                </ul>
            </th>
        </tr>
    </table>

    <!--AF Data Collection-->
		<div id="scf21-iddiv"></div>
    <table id="scf21" data-aos="fade-up">
        <tr>
            <th class="title"></th>
            <th class="content project-title colored">Audience-Feedback Data Collection</th>
        </tr>
        <tr>
            <th class="title colored">affiliation</th>
            <th class="content">
							<a href="https://isl.stanford.edu/" class="colored">Stanford Information Systems Laboratory</a>, 
							<a href="https://compression.stanford.edu" class="colored">Stanford Compression Forum</a>,
							<a href="https://compression.stanford.edu/outreach/stem2shtem-summer-internships-high-schoolers-and-community-college-students" class="colored">Stanford STEM to SHTEM</a>
            </th>
        </tr>
        <tr>
            <th class="title colored">title</th>
            <th class="content">Project Mentor</th>
        </tr>
        <tr>
            <th class="title colored">timeline</th>
            <th class="content">June 2021 - August 2021</th>
        </tr>
        <tr>
            <th class="title colored">Team</th>
            <th class="content">Prof. Tsachy Weissman (Stanford EE) as the Advisor, Ganesh Pimpale (Berkeley CS)</th>
        </tr>
        <tr>
            <th class="title colored">summary</th>
						<th class="content"> Led a group of two highschoolers in developing data collection software for the audience feedback component of the 
							digital puppetry project. The the implemented policies were never put to action, the project was able to give the students a brief introduction
							to information theory and experience with browser-side processing. 
						</th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">publication</th>
            <th class="content">
                <ul>
                    <li>The Informaticists Scientific Journal - <a
                            href="https://theinformaticists.com/2021/08/21/facial-landmark-data-collection-to-train-facial-emotion-detection-learning-models/"
                            class="colored">https://theinformaticists.com/2021/08/21/facial-landmark-data-collection-to-train-facial-emotion-detection-learning-models/</a>
                    </li>
                </ul>
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">abstract</th>
            <th class="content">A subteam was created within the Digital Puppetry group to deal with the task of processing digital audience reactionary
							information, consisting of myself and a group of Stanford researchers and Industry members. We decided to bring the project to STEM to SHTEM 
							interns, to see if they would be able to add new insights to the project. Their review is comprehensive, but is geared towards the
							technical specifics of implementing data collection and storing computer data, not towards novelity within the field of audience feedback. The
							idea was to collect training data for a model which, when deployed, would be able to autonomously collect reactionary states during a live
							virtual performance (similar to Stanford TAPS's 2020 virtual performance). Both interns decided to continue working on the project upon the termination
							of the STEM to SHTEM program.
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">project</th>
            <th class="content">
                <ul>
                    <li><a href="https://github.com/roshanprabhakar/af-datacollection" class="colored">https://github.com/roshanprabhakar/af-datacollection</a>
                    </li>
                </ul>
            </th>
        </tr>
    </table>

    <!--txt2vid-browser-->
		<div id="txt2vid-browser-iddiv"></div>
    <table id="txt2vid-browser" data-aos="fade-up">
        <tr>
            <th class="title"></th>
            <th class="content project-title colored">Txt2Vid for Mobile Devices</th>
        </tr>
        <tr>
            <th class="title colored">affiliation</th>
            <th class="content">
							<a href="https://isl.stanford.edu/" class="colored">Stanford Information Systems Laboratory</a>, 
							<a href="https://ee.stanford.edu/academics/reu" class="colored">Stanford EE REU Program</a>
							<a href="https://compression.stanford.edu" class="colored">Stanford Compression Forum</a>,
							<a href="https://compression.stanford.edu/outreach/stem2shtem-summer-internships-high-schoolers-and-community-college-students" class="colored">Stanford STEM to SHTEM</a>
            </th>
        </tr>
        <tr>
            <th class="title colored">title</th>
            <th class="content">Developer</th>
        </tr>
        <tr>
            <th class="title colored">timeline</th>
            <th class="content">June 2022 - September 2022</th>
        </tr>
        <tr>
            <th class="title colored">Team</th>
            <th class="content">Prof. Tsachy Weissman (Stanford EE); Pulkit Tandon, PhD (Stanford EE); Sahasrajit Sarmasarkar, PhD (Stanford EE); Arjun Barrett, Highschool Senior (Harker)</th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">summary</th>
						<th class="content">This group of people was selected by Tsachy Weissman to work on novel research in the space of information theory. We decided to work on bringing 
							the Txt2Vid concept codec to mobile devices. I brought the project to Stanford EE REU through my participation in the program during the summer.
						</th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">publication</th>
            <th class="content">
                <ul>
                    <li>The Informaticists Scientific Journal - <a
                            href="https://theinformaticists.com/2022/10/04/implementation-and-evaluation-of-ultra-low-bandwidth-video-conferencing-platform-versus-traditional-compression-techniques/
" class="colored">https://theinformaticists.com/2022/10/04/implementation-and-evaluation-of-ultra-low-bandwidth-video-conferencing-platform-versus-traditional-compression-techniques/</a>
                    </li>
										<li>Presented to the REU EE research body</li>
										<li>pending conference publication...</li>
                </ul>
            </th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">abstract</th>
						<th class="content"> 
							Txt2Vid is a novel codec intended for video conferencing applications proposed by Pulkit Tandon in his line of 
							studies. The basic schema involves an encoder responsible for providing a loopable driver video and a text-transcript representing the audio stream. The decoder
							reconstructs a new video by looping the driving video indefinitely, constructing a raw audio stream from the text transcript, then lip-syncing the driving
							video with the reconstructed audio. His project demonstrated the viability of this idea with a p.o.c implementation. Our work involved bringing his implementation
							to mobile devices. This required: reimplementing local preprocessing in javascript, porting the lip-syncing model to a gpu-boosted browser runtime (we chose WONNX), 
							and implementing unsupported ONNX functions for the WONNX runtime. Currently the codec is deployed as a demo streaming service demonstrating the viability of the 
							model in bandwidth-constrained environments. The project is ongoing.
						</th>
        </tr>
        <tr class="padder"></tr>
        <tr>
            <th class="title colored">project</th>
            <th class="content">
                <ul>
                    <li><a href="https://github.com/tpulkit/txt2vid/tree/arjun-browser" class="colored">https://github.com/tpulkit/txt2vid/tree/arjun-browser</a>
                    </li>
										<li><a href="https://github.com/101arrowz/send-it/tree/real-txt2vid" class="colored">https://github.com/101arrowz/send-it/tree/real-txt2vid</a>
										</li>
										<li><a href="https://github.com/roshanprabhakar/txt2vid-VideoHandler" class="colored">https://github.com/roshanprabhakar/txt2vid-VideoHandler</a>
										</li>
                </ul>
            </th>
        </tr>
    </table>

</div>

<!--
<a href="res/Resume.pdf" target="_blank" id="cv" data-aos="fade-up">My Resume</a>
-->

<div class="padder" style="height: 50px;"></div>

<script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script>
    AOS.init();
</script>
<script src="scripts/index.js"></script>
</body>
</html>
